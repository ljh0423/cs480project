{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7510caa5a04442da92b6ac6d2ab52ee5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3fcee7ec9204d86b3d26dadfa719096","IPY_MODEL_bd720f790f474d988b064d5542530c23","IPY_MODEL_a1f4d7e7d6a44289be06017b0e425db0"],"layout":"IPY_MODEL_ffda5bb622ff420d9dd33061f3d1982a"}},"c3fcee7ec9204d86b3d26dadfa719096":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a3a96b69cf84e61b4d500d6c8985f00","placeholder":"​","style":"IPY_MODEL_79511cd2345a4f00a5f47d8bfb4aa7ec","value":"model.safetensors: 100%"}},"bd720f790f474d988b064d5542530c23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_551d97da045d4f67994351eb808d667b","max":36494688,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f54dd5f72b6e4ae68eeec7f6fd3c6a04","value":36494688}},"a1f4d7e7d6a44289be06017b0e425db0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72976b1cdedb443da3db64c3a2a41581","placeholder":"​","style":"IPY_MODEL_31e014c4a50240ac917e4e394f88c879","value":" 36.5M/36.5M [00:00&lt;00:00, 94.8MB/s]"}},"ffda5bb622ff420d9dd33061f3d1982a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a3a96b69cf84e61b4d500d6c8985f00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79511cd2345a4f00a5f47d8bfb4aa7ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"551d97da045d4f67994351eb808d667b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f54dd5f72b6e4ae68eeec7f6fd3c6a04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72976b1cdedb443da3db64c3a2a41581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31e014c4a50240ac917e4e394f88c879":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":81655,"databundleVersionId":8915386,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##Model 1","metadata":{"id":"7klBv4BqJox7"}},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms.v2 as transforms\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nimport matplotlib.pyplot as plt\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"id":"mMwsPObbZNdR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21494d71-3a25-4429-a40f-d1d9eea7ad45","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_col = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\noutput_col_test = ['X4', 'X11', 'X18', 'X26', 'X50', 'X3112']","metadata":{"id":"aCpx_eJ1lwcU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load data\ndatapath = '/kaggle/input/cs-480-2024-spring/data/'\ntrain = pd.read_csv(datapath + 'train.csv')\ntrain['path'] = [datapath + 'train_images/'+str(int(e))+'.jpeg' for e in train['id'].values]\n\ntest = pd.read_csv(datapath + 'test.csv')\ntest['path'] = [datapath + 'test_images/'+str(int(e))+'.jpeg' for e in test['id'].values]\n\ninput_col = test.columns.values[1:-1]\n\ntrain, val = train_test_split(train, test_size=4000, shuffle=True)","metadata":{"id":"V3t7T5CgfTx3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 6\nn_batch_size = 24\nn_display_step = 10\nn_learning_rate = 0.0001","metadata":{"id":"Nt400Crz2Apd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Outlier handling\n\nfor column in output_col:\n    lower_quantile = train[column].quantile(0.001)\n    upper_quantile = train[column].quantile(0.999)\n    train_f = train[(train[column] > lower_quantile) & (train[column] < upper_quantile)]\n    val_f = val[(val[column] > lower_quantile) & (val[column] < upper_quantile)]\n\n\nprint(train_f.shape)\nprint(val_f.shape)\n\nlog_feat = ['X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n\ndef norm(y, df):\n    for i, target in enumerate(output_col):\n        col = df[target]\n        if target in log_feat:\n            col = np.log10(col)\n        shift[i] = np.mean(col)\n        col = col - shift[i]\n        scale[i] = np.std(col)\n        col = col / scale[i]\n        y[:,i] = col\n    return y\n\ndef denormalize(output, target):\n    # Scale Back\n    output = (output * scale) + shift\n    # Log Scale\n    output = torch.where(torch.tensor(np.isin(output_col, log_feat)).to(device), 10**output, output)\n    target = (target * scale) + shift\n    target = torch.where(torch.tensor(np.isin(output_col, log_feat)).to(device), 10**target, target)\n    return output, target\n\nshift = np.zeros(6)\nscale = np.zeros(6)\n\n# Normalize the target columns\ny_train_norm = norm(np.zeros_like(train_f[output_col]), train_f)\ny_val_norm = norm(np.zeros_like(val_f[output_col]), val_f)\n\nscale = torch.from_numpy(scale).to(device)\nshift = torch.from_numpy(shift).to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O93KG4GembTG","outputId":"aa7fb70c-e45f-4c5e-c27e-6665a1d4e1cf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale\nscaler = StandardScaler()\nx_train = scaler.fit_transform(train_f[input_col].values.astype(np.float32))\n# Transform val/test features using scaler fitted on train data\nx_val = scaler.transform(val_f[input_col].values.astype(np.float32))\nx_test = scaler.transform(test[input_col].values.astype(np.float32))\n# Convert Features to Torch Tensors\nx_train = torch.tensor(x_train)\nx_val = torch.tensor(x_val)\nx_test = torch.tensor(x_test)\n","metadata":{"id":"TeVdcuNXvVnV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = transforms.Compose(\n    [\n        transforms.Resize((288, 288)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ]\n)\n# For training, we add some augmentation. Networks are too powerful and would overfit.\ntrain_transform = transforms.Compose(\n    [\n        transforms.Resize((288, 288)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter((0.9,1.1), (0.9,1.1)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ]\n)","metadata":{"id":"l6TH2FjzDfc6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ef61c28-e4c8-43a3-d55c-25bb1dd25965","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, data_im, data_num, data_out, transform=None, mode='m1train'):\n        self.data_im = data_im\n        self.data_num = data_num\n        self.data_out = data_out\n        self.transform = transform\n        self.mode = mode\n\n    def __getitem__(self, index):\n        if 'm2' in self.mode:\n            x = self.transform(Image.open(self.data_im[index]))\n        else:\n            x = (self.transform(Image.open(self.data_im[index])).float(), self.data_num[index].float())\n        if 'test' in self.mode:\n            y = self.data_out[index]\n        else:\n            y = torch.from_numpy(self.data_out[index]).float()\n        return x, y\n\n    def __len__(self):\n        return len(self.data_im)","metadata":{"id":"Liq8hcu8fV9t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = MyDataset(train_f['path'].values, x_train, y_train_norm, train_transform)\nval_dataset = MyDataset(val_f['path'].values, x_val, y_val_norm, test_transform)\ntest_dataset = MyDataset(test['path'].values, x_test, test['id'].values, test_transform, 'm1test')\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=n_batch_size, drop_last=True)\n\nval_dataloader = DataLoader(val_dataset, batch_size=n_batch_size, drop_last=False)\n","metadata":{"id":"nhBk75nJG68c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Backbone\n        self.effvit = timm.create_model(\n                'efficientvit_b1.r288_in1k',\n                pretrained=True,\n                num_classes=0\n            )\n        self.effvit.head = self.effvit.head.global_pool\n\n        # Features\n        self.nn = nn.Sequential(\n            nn.Linear(163,256),\n            nn.GELU(),\n            nn.Linear(256,256),\n        )\n\n        # Label\n        self.combnn = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.GELU(),\n            nn.Linear(256,256),\n            nn.GELU(),\n            nn.Linear(256,6, bias=False)\n        )\n\n        # Initialize Weights\n        self.initialize_weights()\n\n    def initialize_weights(self):\n        nn.init.kaiming_uniform_(self.nn[0].weight)\n        nn.init.zeros_(self.combnn[0].weight)\n\n    def forward(self, input):\n        x1 = self.effvit(input[0])\n        x2 = self.nn(input[1])\n        x = torch.cat((x1, x2), dim=1)\n        x = self.combnn(x)\n        return x\nmodel1 = Model()\nmodel1.to(device)","metadata":{"id":"VOrYa54E2lmb","colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["7510caa5a04442da92b6ac6d2ab52ee5","c3fcee7ec9204d86b3d26dadfa719096","bd720f790f474d988b064d5542530c23","a1f4d7e7d6a44289be06017b0e425db0","ffda5bb622ff420d9dd33061f3d1982a","1a3a96b69cf84e61b4d500d6c8985f00","79511cd2345a4f00a5f47d8bfb4aa7ec","551d97da045d4f67994351eb808d667b","f54dd5f72b6e4ae68eeec7f6fd3c6a04","72976b1cdedb443da3db64c3a2a41581","31e014c4a50240ac917e4e394f88c879"]},"outputId":"dad6cb9d-5420-40a8-d5b0-31e4d14011c8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def r2loss(output, target):\n    target_mean = torch.mean(target, dim=0)\n    ss_tot = (target - target_mean) ** 2\n    ss_res = (target - output) ** 2\n    loss = torch.sum(ss_res, dim=0) / torch.maximum(torch.sum(ss_tot, dim=0), torch.tensor([0.000001]).to(device))\n    return torch.mean(loss)","metadata":{"id":"Ft37GiKD3ZGV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the learning rate scheduler\ndef lr_sc(optimizer):\n    return torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer,\n        max_lr=1e-4,\n        total_steps=len(train_dataset)//n_batch_size * n_epochs + 1,\n        pct_start=0.10,\n        anneal_strategy='cos',\n        div_factor=1e3,\n        final_div_factor=1e4,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.AdamW(model1.parameters(), lr=n_learning_rate, weight_decay=0.01)\ncriterion = r2loss\nlrsc = lr_sc(optimizer)","metadata":{"id":"bcwie4uIl1cu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_r2(model, loader, mode):\n    model.eval()\n    n_samples = 0\n    n_correct = 0\n    res = []\n    tar = []\n\n    with torch.no_grad():\n        test_loss = []\n        for step, (x, target) in enumerate(loader):\n            x = (x[0].to(device), x[1].to(device))\n            target = target.to(device)\n            output = model(x)\n            output, target = denormalize(output, target)\n            res.extend(output.detach().cpu())\n            tar.extend(target.detach().cpu())\n            loss = criterion(output, target)\n            if step % n_display_step == 0:\n                print('\\rloss: ', loss.item(), end='')\n    tar = np.array(tar)\n    res = np.array(res)\n    print([r2_score(tar[:,i],res[:,i]) for i in range(6)])\n    return [r2_score(tar[:,i],res[:,i]) for i in range(6)]\n\n# function to train the net\ndef train_model(model, criterion, optimizer, epochs, train_loader, val_loader):\n    for epoch in range(epochs):\n        model.train()\n        for step, (x, target) in enumerate(train_loader):\n            x = (x[0].to(device), x[1].to(device))\n            target = target.to(device)\n            output = model(x)\n            output, target = denormalize(output, target)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            lrsc.step()\n\n            if step % n_display_step == 0:\n                print(\"\rEpoch {:2d} Step {:4d} Loss {:.4f}\".format(epoch, step, loss.item()), f'{lrsc.get_last_lr()[0]:.2e}', end='')\n        val_acc = get_r2(model, val_loader, 'test')\n        print(\"Epoch {:2d} Loss {:.4f} Accuracy (Train | Test) {:.4f} {:.4f}\".format(epoch, loss.item(), val_acc))\n\ntrain_model(model1, criterion, optimizer, n_epochs, train_dataloader, val_dataloader)","metadata":{"id":"4BTNx19qmHT7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model1.state_dict(), 'model1.pth')","metadata":{"id":"KIA__bVpoydC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.eval()\ntest_output=[]\nwith torch.no_grad():\n    for step, (x, target_id) in enumerate(test_dataset):\n        x = (x[0].unsqueeze(0).to(device), x[1].unsqueeze(0).to(device))\n        output = model1(x).squeeze(0)\n        output, _ = denormalize(output, output)\n        test_output.append(np.append(np.array(target_id),output.cpu()))\n\ndf = pd.DataFrame(test_output, columns=['id']+output_col_test)\ndf['id'] = df['id'].astype(int)\ndf.to_csv('submissionm1.csv', index=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"A-um7a4dNn8p","outputId":"5f18a887-900b-444c-d773-3d58d9b57158","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
